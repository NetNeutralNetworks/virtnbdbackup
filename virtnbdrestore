#!/usr/bin/env python3
import os
import sys
import nbd
import json
import logging
import argparse
import pprint
from time import sleep

import libvirtnbdbackup.common as common
import libvirtnbdbackup.nbdhelper as nbdhelper
import libvirtnbdbackup.libvirthelper as virtclient
import libvirtnbdbackup.sparsestream  as sparsestream
import libvirtnbdbackup.qemuhelper as qemuhelper

def main():
    logging.getLogger("sh").setLevel(logging.WARNING)
    parser = argparse.ArgumentParser(description='Restore')
    parser.add_argument("-a", "--action", required=True,
        choices=['dump','restore'],
        type=str,
        help="Actions")
    parser.add_argument("-i", "--input", required=True,
        type=str,
        help="Directory including a backup set")
    parser.add_argument("-o", "--output", required=True,
        type=str,
        help="Restore target directory")
    parser.add_argument("-u", "--until", required=False,
        type=str,
        help="Restore only until checkpoint, point in time restore")
    parser.add_argument("-v", "--verbose", required=False,
        action="store_true",
        default=False,
        help="Enable debug output")

    try:
        args = parser.parse_args()
    except:
        parser.print_help()
        sys.exit(1)

    logger = logging
    if args.verbose == True:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.basicConfig(level=level)

    if not os.path.exists(args.input):
        logger.error("Backup set directory does not exist")
        sys.exit(1)

    lib = common.Common()
    if args.action == "dump":
        logger.info("Dumping saveset meta information")
        dataFiles = lib.getDataFiles(args.input)
        for dataFile in dataFiles:
            pprint.pprint(lib.dumpMetaData(dataFile, sparsestream))

    if args.action == "restore":
        logger.info("Read latest config file")
        vmConfig = lib.getLastConfigFile(args.input)
        if not vmConfig:
            logger.error("No domain config file found")
            sys.exit(1)

        with open(vmConfig,'r') as vmConf:
            vmDisks = virtclient.client().getDomainDisks(vmConf.read())

        for disk in vmDisks:
            restoreDisk = lib.getDataFilesByDisk(args.input, disk.diskTarget)
            if not "full" in restoreDisk[0]:
                logger.error("Unable to find full backup")
                sys.exit(1)
            meta = lib.dumpMetaData(restoreDisk[0], sparsestream)
            logger.info("Create virtual Disk %s/%s" % (args.output,meta['diskName']))
            logger.info("Size %s" % meta['virtualSize'])
            qFh = qemuhelper.qemuHelper(meta['diskName'])

            try:
                qFh.create(args.output, meta['virtualSize'])
            except Exception as e:
                logger.error("Cant create restore target: %s" % e)
                sys.exit(1)

            logger.info("Starting nbd server")
            try:
                nbdSrv = qFh.startNbdServer(args.output)
            except Exception as e:
                logger.error("Unable to start nbd server: %s" %e)
                sys.exit(1)

            logging.info("Waiting until nbd server is up")
            sleep(5)

            nbdClient = nbdhelper.nbdClient(meta['diskName'],None)
            connection = nbdClient.connect()

            for restoreFile in restoreDisk:
                reader = open(restoreFile,'rb')
                kind, start, length = sparsestream.SparseStream().read_frame(
                    reader
                )
                meta = sparsestream.SparseStream().load_metadata(reader.read(
                    length
                ))
                if meta['dataSize'] == 0:
                    logger.info("Saveset %s contains no dirty blocks, skipping" % restoreFile)
                    continue
                logger.info("Applying data from file %s" % restoreFile)
                pprint.pprint(meta)
                assert reader.read(len(sparsestream.SparseStreamTypes().TERM)) == sparsestream.SparseStreamTypes().TERM
                dataSize = 0
                while True:
                    kind, start, length = sparsestream.SparseStream().read_frame(reader)
                    if kind == sparsestream.SparseStreamTypes().ZERO:
                        continue
                    elif kind == sparsestream.SparseStreamTypes().DATA:
                        logger.info("Write data segment from %s length: %s" % (start,length))
                        if length >= nbdClient.maxRequestSize:
                            bs = nbdClient.minRequestSize
                            assert length % nbdClient.minRequestSize == 0
                            count = int(length/bs)
                            ct = 1
                            offset = start
                            while ct <= count:
                                ct+=1
                                data = reader.read(bs)
                                connection.pwrite(data, offset)
                                offset += nbdClient.minRequestSize
                        else:
                            data = reader.read(length)
                            connection.pwrite(data, start)
                        assert reader.read(len(sparsestream.SparseStreamTypes().TERM)) == sparsestream.SparseStreamTypes().TERM
                        dataSize += length
                    elif kind == sparsestream.SparseStreamTypes().STOP:
                        logger.info("End of stream, %s data processed" % dataSize)
                        break

                if meta['checkpointName'] == args.until:
                    logging.info("Reached checkpoint %s, stopping" % args.until)
                    break

            nbdClient.disconnect()

if __name__ == "__main__":
    main()
