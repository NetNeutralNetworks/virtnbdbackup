#!/usr/bin/env python3
import os
import sys
import nbd
import json
import logging
import argparse
import pprint
from time import sleep

import libvirtnbdbackup.common as common
import libvirtnbdbackup.nbdhelper as nbdhelper
import libvirtnbdbackup.libvirthelper as virtclient
import libvirtnbdbackup.sparsestream  as sparsestream
import libvirtnbdbackup.qemuhelper as qemuhelper

def main():
    logging.getLogger("sh").setLevel(logging.WARNING)
    parser = argparse.ArgumentParser(
        description='Restore virtual machine disks'
    )
    parser.add_argument("-a", "--action", required=True,
        choices=['dump','restore'],
        type=str,
        help="Action to perform")
    parser.add_argument("-i", "--input", required=True,
        type=str,
        help="Directory including a backup set")
    parser.add_argument("-o", "--output", required=True,
        type=str,
        help="Restore target directory")
    parser.add_argument("-u", "--until", required=False,
        type=str,
        help="Restore only until checkpoint, point in time restore")
    parser.add_argument("-v", "--verbose", required=False,
        action="store_true",
        default=False,
        help="Enable debug output")

    try:
        args = parser.parse_args()
    except:
        sys.exit(1)

    logger = logging
    if args.verbose == True:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.basicConfig(level=level)

    if not os.path.exists(args.input):
        logger.error("Backup set directory does not exist")
        sys.exit(1)

    lib = common.Common()
    if args.action == "dump":
        logger.info("Dumping saveset meta information")
        dataFiles = lib.getDataFiles(args.input)
        for dataFile in dataFiles:
            meta = lib.dumpMetaData(dataFile, sparsestream)
            if meta is False:
                logger.error('Unable to dump image contents, image defunct or raw image?')
                continue
            pprint.pprint(meta)

    if args.action == "restore":
        logger.info("Read latest config file")
        vmConfig = lib.getLastConfigFile(args.input)
        if not vmConfig:
            logger.error("No domain config file found")
            sys.exit(1)

        with open(vmConfig,'r') as vmConf:
            vmDisks = virtclient.client().getDomainDisks(vmConf.read())

        for disk in vmDisks:
            restoreDisk = lib.getDataFilesByDisk(args.input, disk.diskTarget)
            if len(restoreDisk) < 1:
                logger.warning("Did not find any backups for disk image %s" % disk.diskTarget)
                continue
            if not "full" in restoreDisk[0] and not "copy" in restoreDisk[0]:
                logger.error("Unable to find base dataset.")
                sys.exit(1)
            meta = lib.dumpMetaData(restoreDisk[0], sparsestream)
            logger.info("Create virtual Disk %s/%s" % (args.output,meta['diskName']))
            logger.info("Size %s" % meta['virtualSize'])
            qFh = qemuhelper.qemuHelper(meta['diskName'])

            try:
                qFh.create(args.output, meta['virtualSize'])
            except Exception as e:
                logger.error("Cant create restore target: %s" % e)
                sys.exit(1)

            logger.info("Starting nbd server")
            try:
                nbdSrv = qFh.startNbdServer(args.output)
            except Exception as e:
                logger.error("Unable to start nbd server: %s" %e)
                sys.exit(1)

            logging.info("Waiting until nbd server is up")
            sleep(5)

            nbdClient = nbdhelper.nbdClient(meta['diskName'],None)
            connection = nbdClient.connect()

            for restoreFile in restoreDisk:
                reader = open(restoreFile,'rb')
                kind, start, length = sparsestream.SparseStream().read_frame(
                    reader
                )
                meta = sparsestream.SparseStream().load_metadata(reader.read(
                    length
                ))
                if meta['dataSize'] == 0:
                    logger.info("Saveset %s contains no dirty blocks, skipping" % restoreFile)
                    continue
                logger.info("Applying data from file %s" % restoreFile)
                pprint.pprint(meta)
                assert reader.read(len(sparsestream.SparseStreamTypes().TERM)) == sparsestream.SparseStreamTypes().TERM
                dataSize = 0
                while True:
                    kind, start, length = sparsestream.SparseStream().read_frame(
                        reader
                    )
                    if kind == sparsestream.SparseStreamTypes().ZERO:
                        logger.info("Write zero segment from %s length: %s" % (
                            start,
                            length
                        ))
                        if length >= nbdClient.maxRequestSize:
                            logger.debug("Chunked zero, start: %s, len: %s" %(
                                start,
                                length
                            ))
                            lib.zeroChunk(
                                start,
                                length,
                                nbdClient.maxRequestSize,
                                connection
                            )
                        else:
                            connection.zero(length, start)
                    elif kind == sparsestream.SparseStreamTypes().DATA:
                        logger.info("Write data segment from %s length: %s" % (start,length))
                        if length >= nbdClient.maxRequestSize:
                            logger.debug("Chunked read/write, start: %s, len: %s" %(
                                start,
                                length
                            ))
                            lib.readChunk(
                                reader,
                                start,
                                length,
                                nbdClient.maxRequestSize,
                                connection
                            )
                        else:
                            data = reader.read(length)
                            connection.pwrite(data, start)
                        assert reader.read(len(sparsestream.SparseStreamTypes().TERM)) == sparsestream.SparseStreamTypes().TERM
                        dataSize += length
                    elif kind == sparsestream.SparseStreamTypes().STOP:
                        if dataSize == meta['dataSize']:
                            logger.info("End of stream, %s bytes of data processed" % dataSize)
                        else:
                            logger.error('Error: restored data size %s != %s' % (
                                dataSize,
                                meta['dataSize']
                            ))
                            sys.exit(1)
                        break

                if meta['checkpointName'] == args.until:
                    logging.info("Reached checkpoint %s, stopping" % args.until)
                    break

            nbdClient.disconnect()

if __name__ == "__main__":
    main()
