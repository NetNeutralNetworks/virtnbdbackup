#!/usr/bin/env python3
import os
import sys
import json
import pprint
import logging
import argparse

import libvirtnbdbackup.common as common
import libvirtnbdbackup.nbdhelper as nbdhelper
import libvirtnbdbackup.extenthandler as extenthandler
import libvirtnbdbackup.sparsestream  as sparsestream
import libvirtnbdbackup.qemuhelper as qemuhelper
import libvirtnbdbackup.libvirthelper as libvirthelper

def main():
    logging.getLogger("sh").setLevel(logging.WARNING)
    parser = argparse.ArgumentParser(
        description='Backup libvirt/qemu virtual machines'
    )
    parser.add_argument("-d", "--domain", required=True,
        type=str,
        help="Domain to backup")
    parser.add_argument("-l", "--level", default="copy",
        choices=['copy','full','inc'],
        type=str,
        help="Backup level, defaults to copy")
    parser.add_argument("-t", "--type", default="stream",
        choices=['stream','raw'],
        type=str,
        help="Output type: stream or raw")
    parser.add_argument("-o", "--output", required=True,
        type=str,
        help="Output target directory")
    parser.add_argument("-S", "--scratchdir", required=False,
        type=str,
        help="Target directory for temporary scratch file",
        default="/tmp/")
    parser.add_argument("-q", "--qemu", default=False,
        help="Use Qemu tools to query extents",
        action="store_true")
    parser.add_argument("-i", "--include", default=None,
        type=str,
        help="Backup only disk with target dev name specified")
    parser.add_argument("-c", "--checkpoint", default=False,
        help="During incremental backup, use specified checkpoint as parent",
        type=str)
    parser.add_argument("-s", "--startonly", default=False,
        help="Only initialize backup job via libvirt, do not backup any data",
        action="store_true")
    parser.add_argument("-k", "--killonly", default=False,
        help="Kill any running block job",
        action="store_true")
    parser.add_argument("-p", "--printonly", default=False,
        help="Quit after printing extent information",
        action="store_true")
    parser.add_argument("-v", "--verbose", default=False,
        help="Enable debug output",
        action="store_true")

    lib = common.Common()
    args = lib.argparse(parser)

    logger = logging
    if args.verbose == True:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logger.basicConfig(level=level)

    if args.type == "raw" and args.level == "inc":
        logger.error("Backup format raw does not support incremental backup")
        sys.exit(1)

    if not args.output == "-":
        if not lib.targetIsEmpty(args):
            logger.error("Target directory must empty")
            sys.exit(1)

    virtClient = libvirthelper.client()
    try:
        domObj = virtClient.getDomain(args.domain)
    except Exception as e:
        logging.error('Unable to get domain information: %s' % e)
        sys.exit(1)

    if virtClient.hasIncrementalEnabled(domObj) == False:
        logger.error("Domain is missing required incremental-backup capability.")
        sys.exit(1)

    vmConfig = virtClient.getDomainConfig(domObj)
    disks = virtClient.getDomainDisks(vmConfig)

    logger.info("Domain has %s disks attached which support changed block tracking." % len(disks))

    if args.killonly == True:
        logger.info("Stopping domain jobs")
        try:
            virtClient.stopBackup(domObj, disks[0].diskTarget)
        except Exception as e:
            logging.warn('%s' % e)
        sys.exit(0)

    if not os.path.exists(args.output):
        try:
            os.mkdir(args.output)
        except Exception as e:
            logger.error("%s" % e)
            sys.exit(1)

    checkpointName = "virtnbdbackup"
    parentCheckpoint = False
    checkpoints = []
    cptFile = '%s/%s.cpt' % (args.output, args.domain)
    if os.path.exists(cptFile):
        with open(cptFile,'r') as cptFh:
             checkpoints = json.loads(cptFh.read())

    if args.level != "copy":
        logging.info('Looking for checkpoints')
        if args.level == "full" and len(checkpoints) > 0:
            logging.info("Removing all existant checkpoints before full backup")
            virtClient.removeAllCheckpoints(domObj, checkpoints)
            os.remove(cptFile)
            checkpoints = []
        elif args.level == "full" and len(checkpoints) < 1:
            virtClient.removeAllCheckpoints(domObj,None)
            checkpoints = []

        if len(checkpoints) > 0 and args.level == "inc":
            nextCpt = len(checkpoints)+1
            checkpointName = "virtnbdbackup.%s" % nextCpt
            if args.checkpoint != False:
                logging.info("Overriding checkpoint: %s" % args.checkpoint)
                parentCheckpoint = args.checkpoint
            else:
                parentCheckpoint = checkpoints[-1]
            logging.info('Found checkpoints, next name: %s' % nextCpt)
            logging.info("Parent checkpoint name %s" % parentCheckpoint)

        if args.level == "inc" and len(checkpoints)<1:
            logger.error("No prior checkpoints found, execute full backup first")
            sys.exit(1)

        logging.info("Using checkpoint name %s" % checkpointName)

    logging.info('Temporary scratch file target directory: %s' % args.scratchdir)

    if not os.path.exists(args.scratchdir):
        try:
            os.mkdir(args.scratchdir)
        except Exception as e:
            logging.error('Unable to create directory for scratch file: %s' % e)
            sys.exit(1)

    try:
        virtClient.startBackup(domObj, disks, args.level,
                               checkpointName, parentCheckpoint,
                               args.scratchdir)
    except Exception as e:
        logging.error('%s' % e)
        sys.exit(1)

    if args.level != "copy":
        logging.info('Started backup with checkpoint, saving information')
        if len(checkpoints) < 1:
            checkpoints = []
        checkpoints.append(checkpointName)
        with open(cptFile,'w') as cFw:
            cFw.write(json.dumps(checkpoints))

    if args.startonly == True:
        logging.info("Exiting after backup Start")
        sys.exit(0)

    for disk in disks:
        if args.include != None and disk.diskTarget != args.include:
            logging.info("Skipping disk: %s" % disk.diskTarget)
            continue
        try:
            backupDisk(disk.diskTarget, args, lib, logger,
                       checkpointName, parentCheckpoint)
        except Exception as e:
            logger.error('%s' % e)
            virtClient.stopBackup(domObj, disk.diskTarget)
            sys.exit(1)
    if args.printonly is False and args.output != "-":
        backupConfig(vmConfig, args, checkpointName, logger)
    virtClient.stopBackup(domObj, disk.diskTarget)

def backupConfig(vmConfig, args, checkpointName, logger):
    configFile = '%s/vmconfig.%s.xml' % (args.output, checkpointName)
    logger.info("Saving VM config to: %s" % configFile)
    with open(configFile, 'w') as configFh:
        configFh.write(vmConfig)

def backupDisk(diskTarget, args, lib, logger, checkpointName, parentCheckpoint):
    metaContext = None
    if args.level == "inc":
        metaContext = "qemu:dirty-bitmap:backup-%s" % diskTarget
        logger.info("INC backup: set context to %s" % metaContext)

    nbdClient = nbdhelper.nbdClient(diskTarget, metaContext)
    connection = nbdClient.connect()

    if args.qemu and args.level != "inc":
        logger.info("Using qemu tools to query extents")
        extentHandler = extenthandler.ExtentHandler(
            qemuhelper.qemuHelper(diskTarget),
            metaContext)
    else:
        logger.info("Using nbd to query extents")
        extentHandler = extenthandler.ExtentHandler(
            connection,
            metaContext
        )
    extents = extentHandler.queryBlockStatus()
    diskSize = connection.get_size()

    if extents == None:
        logging.error("No extents found")
        return

    thinBackupSize = sum(
        [extent.length for extent in extents if extent.data == True]
    )
    logger.info("Got %s extents" % len(extents))
    if args.verbose == True:
        pprint.pprint(lib.dumpExtentJson(extents))
    logger.info("%s bytes disk size" % diskSize)
    logger.info("%s bytes of data extents to backup" % thinBackupSize)
    if args.printonly == True:
        nbdClient.disconnect()
        return

    if args.level == "inc" and thinBackupSize == 0:
        logger.info("No dirty blocks found")

    if args.level == "full" or args.level == "copy":
        targetFile = '%s/%s.%s.data' % (
            args.output,
            diskTarget,
            args.level
        )
    elif args.level == "inc":
        targetFile = '%s/%s.inc.%s.data' % (
            args.output,
            diskTarget,
            checkpointName
        )

    if args.output == '-':
        if args.type == 'stream':
            writer = sys.stdout.buffer
        else:
            logger.error('Stdout not supported with raw output')
    else:
        logger.info("Write data to target file: %s" % targetFile)
        writer = open(targetFile,'wb')
    if args.type == "raw":
        logging.info("Creating full provisioned raw backup image")
        writer.truncate(diskSize)
        writer.seek(0)
    else:
        logging.info("Creating thin provisioned stream backup image")
        inc = False
        if args.level == "inc":
            inc = True
        metadata = sparsestream.SparseStream().dumpMetadata(diskSize,
            thinBackupSize, diskTarget, checkpointName,
            parentCheckpoint, inc)
        sparsestream.SparseStream().writeFrame(writer,
            sparsestream.SparseStreamTypes().META,
            0,
            len(metadata)
        )
        writer.write(metadata)
        writer.write(sparsestream.SparseStreamTypes().TERM)

    for save in extents:
        if save.data == True:
            if args.type == "stream":
                sparsestream.SparseStream().writeFrame(writer,
                    sparsestream.SparseStreamTypes().DATA,
                    save.offset,
                    save.length
                )
                logger.debug("Read data from: start %s, length: %s" % (
                    save.offset,
                    save.length
                ))
            if save.length >= nbdClient.maxRequestSize:
                lib.writeChunk(writer, save.offset, save.length,
                               nbdClient.maxRequestSize, connection,
                               args.type)
            else:
                if args.type == "raw":
                    writer.seek(save.offset)
                writer.write(connection.pread(
                    save.length,
                    save.offset
                ))
            if args.type == "stream":
                writer.write(sparsestream.SparseStreamTypes().TERM)
        else:
            if args.type == "raw":
                writer.seek(save.offset)
            elif args.type == "stream" and args.level != "inc":
                sparsestream.SparseStream().writeFrame(writer,
                    sparsestream.SparseStreamTypes().ZERO,
                    save.offset,
                    save.length
                )
    if args.type == "stream":
        sparsestream.SparseStream().writeFrame(
            writer,
            sparsestream.SparseStreamTypes().STOP,
            0,
            0
        )

    writer.close()

if __name__ == "__main__":
    main()
