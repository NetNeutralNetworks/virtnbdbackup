#!/usr/bin/python3
"""
    Copyright (C) 2021  Michael Ablassmeier <abi@grinser.de>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""
import os
import sys
import json
import signal
import logging
import argparse
from argparse import Namespace
from time import time
from datetime import datetime
from functools import partial
from threading import current_thread
from concurrent.futures import ThreadPoolExecutor, as_completed

from libvirtnbdbackup import __version__
from libvirtnbdbackup import common
from libvirtnbdbackup import nbdhelper
from libvirtnbdbackup import extenthandler
from libvirtnbdbackup import qemuhelper
from libvirtnbdbackup import libvirthelper
from libvirtnbdbackup import outputhelper
from libvirtnbdbackup import exceptions
from libvirtnbdbackup.logcount import logCount
from libvirtnbdbackup.sparsestream import streamer
from libvirtnbdbackup.sparsestream import types


def handleSignal(args, domObj, virtClient, log, signum, _):
    """Catch signal, attempt to stop running backup job."""
    log.error("Caught signal: %s", signum)
    log.error("Cleanup: Stopping backup job")
    if args.offline is not True:
        virtClient.stopBackup(domObj)
    sys.exit(1)


def checkForeign(args, virtClient, domObj, lib):
    """Check and warn user if virtual machine has checkpoints
    not originating from this utility"""
    foreign = None
    if args.level in ("full", "inc", "diff"):
        foreign = virtClient.hasforeignCheckpoint(domObj, lib.checkpointName)

    if not foreign:
        return True

    logging.fatal("VM has external checkpoint: [%s]", foreign)
    logging.fatal("This checkpoint has not been created by this utility.")
    logging.fatal(
        "To ensure checkpoint chain consistency,"
        "remove existing checkpoints,"
        "and start a new backup chain by creating a full backup."
    )

    raise exceptions.ForeignCeckpointError


def setOfflineArguments(args, domObj):
    """Check if to be saved VM is offline and set
    propper options/overwrite backup mode"""
    args.offline = False
    if domObj.isActive() == 0:
        if args.level == "full":
            logging.warning("Domain is offline, resetting backup options.")
            args.level = "copy"
            logging.info("Backup level: [%s].", args.level)
        args.offline = True


def hasPartial(args, lib):
    """Check if target directory has an partial backup,
    makes backup utility exit errnous in case backup
    type is full or inc"""
    if (
        args.level in ("inc", "diff")
        and args.stdout is False
        and lib.partialBackup(args) is True
    ):
        logging.error("Partial backup found in target directory: [%s]", args.output)
        logging.error("One of the last backups seems to have failed.")
        logging.error("Consider re-executing full backup.")
        return True

    return False


def readCheckpointFile(cFile):
    """Open checkpoint file and read checkpoint
    information"""
    checkpoints = []
    if os.path.exists(cFile):
        with outputhelper.openfile(cFile, "rb") as fh:
            checkpoints = json.loads(fh.read().decode())

    return checkpoints


def handleCheckpoints(args, virtClient, domObj, lib):
    """Checkpoint handling for different backup modes
    to be executed.

    Creates a new namespace in the argparse object,
    for easy pass around in further functions.
    """
    checkpointName = f"{lib.checkpointName}.0"
    parentCheckpoint = False
    cptFile = f"{args.output}/{args.domain}.cpt"
    try:
        checkpoints = readCheckpointFile(cptFile)
    except outputhelper.exceptions.OutputException as e:
        raise exceptions.ReadCheckpointsError(f"Unable to read checkpoint file: {e}")
    except json.decoder.JSONDecodeError as e:
        raise exceptions.ReadCheckpointsError(f"Error loading checkpoint file: {e}")

    if args.offline is False:
        if virtClient.redefineCheckpoints(domObj, args) is False:
            raise exceptions.RedefineCheckpointError("Unable to redefine checkpoints.")

    logging.info("Checkpoint handling.")
    if args.level == "full" and checkpoints:
        logging.info("Removing all existent checkpoints before full backup.")
        if not virtClient.removeAllCheckpoints(
            domObj, checkpoints, args, lib.checkpointName
        ):
            raise exceptions.RemoveCheckpointError("Error during checkpoint removal.")
        os.remove(cptFile)
        checkpoints = []
    elif args.level == "full" and len(checkpoints) < 1:
        if not virtClient.removeAllCheckpoints(domObj, None, args, lib.checkpointName):
            raise exceptions.RemoveCheckpointError("Error during checkpoint removal.")
        checkpoints = []

    if checkpoints and args.level in ("inc", "diff"):
        nextCpt = len(checkpoints)
        checkpointName = f"{lib.checkpointName}.{nextCpt}"
        parentCheckpoint = checkpoints[-1]
        logging.info("Next checkpoint id: [%s].", nextCpt)
        logging.info("Parent checkpoint name [%s].", parentCheckpoint)

        if args.offline is True:
            logging.info("Offline backup, using latest checkpoint, saving only delta.")
            checkpointName = parentCheckpoint

    if args.level == "diff":
        logging.info(
            "Diff backup: saving delta since checkpoint: [%s].", parentCheckpoint
        )

    if args.level in ("inc", "diff") and len(checkpoints) < 1:
        raise exceptions.NoCheckpointsFound(
            "No existing checkpoints found, execute full backup first."
        )

    if args.level in ("full", "inc"):
        logging.info("Using checkpoint name: [%s].", checkpointName)

    args.cpt = Namespace()
    args.cpt.name = checkpointName
    args.cpt.parent = parentCheckpoint
    args.cpt.file = cptFile

    logging.debug("Checkpoint info: [%s].", vars(args.cpt))


def saveCheckpointFile(args):
    """Append created checkpoint to checkpoint
    file"""
    try:
        checkpoints = readCheckpointFile(args.cpt.file)
        checkpoints.append(args.cpt.name)
        with outputhelper.openfile(args.cpt.file, "wb") as cFw:
            cFw.write(json.dumps(checkpoints).encode())
    except exceptions.CheckpointException as e:
        raise exceptions.CheckpointException from e
    except outputhelper.exceptions.OutputException as e:
        raise exceptions.SaveCheckpointError from e


def getFileStream(args, outHelper):
    """Get filehandle for output files based on output
    mode"""
    if args.stdout is False:
        fileStream = outHelper.Directory(args.output)
    else:
        fileStream = outHelper.Zip()
        args.output = "./"
        args.worker = 1
        args.raw = False

    return fileStream


def main():
    """Handle backup operation"""
    parser = argparse.ArgumentParser(
        description="Backup libvirt/qemu virtual machines",
        epilog=(
            "Examples:\n"
            "   # full backup of domain 'webvm' with all attached disks:\n"
            "\t%(prog)s -d webvm -l full -o /backup/\n"
            "   # incremental backup:\n"
            "\t%(prog)s -d webvm -l inc -o /backup/\n"
            "   # differencial backup:\n"
            "\t%(prog)s -d webvm -l diff -o /backup/\n"
            "   # full backup, exclude disk 'vda':\n"
            "\t%(prog)s -d webvm -l full -x vda -o /backup/\n"
            "   # full backup, backup only disk 'vdb':\n"
            "\t%(prog)s -d webvm -l full -i vdb -o /backup/\n"
            "   # full backup, compression enabled:\n"
            "\t%(prog)s -d webvm -l full -z -o /backup/\n"
            "   # full backup, create archive:\n"
            "\t%(prog)s -d webvm -l full -o - > backup.zip\n"
        ),
        formatter_class=argparse.RawTextHelpFormatter,
    )

    opt = parser.add_argument_group("General options")
    opt.add_argument("-d", "--domain", required=True, type=str, help="Domain to backup")
    opt.add_argument(
        "-l",
        "--level",
        default="copy",
        choices=["copy", "full", "inc", "diff", "auto"],
        type=str,
        help="Backup level. (default: %(default)s)",
    )
    opt.add_argument(
        "-t",
        "--type",
        default="stream",
        type=str,
        choices=["stream", "raw"],
        help="Output type: stream or raw. (default: %(default)s)",
    )
    opt.add_argument(
        "-r",
        "--raw",
        default=False,
        action="store_true",
        help="Include full provisioned disk images in backup. (default: %(default)s)",
    )
    opt.add_argument(
        "-o", "--output", required=True, type=str, help="Output target directory"
    )
    opt.add_argument(
        "-C",
        "--checkpointdir",
        required=False,
        default=None,
        type=str,
        help="Persistent libvirt checkpoint storage directory",
    )
    opt.add_argument(
        "-S",
        "--scratchdir",
        default="/var/tmp",
        required=False,
        type=str,
        help="Target dir for temporary scratch file. (default: %(default)s)",
    )
    opt.add_argument(
        "-U",
        "--uri",
        default="qemu:///system",
        required=False,
        type=str,
        help="Libvirt connection URI. (default: %(default)s)",
    )
    opt.add_argument(
        "--user",
        default=None,
        required=False,
        type=str,
        help="User used to authenticate against libvirtd. (default: %(default)s)",
    )
    opt.add_argument(
        "--password",
        default=None,
        required=False,
        type=str,
        help="Password used to authenticate against libvirtd. (default: %(default)s)",
    )
    opt.add_argument(
        "-i",
        "--include",
        default=None,
        type=str,
        help="Backup only disk with target dev name (-i vda)",
    )
    opt.add_argument(
        "-x",
        "--exclude",
        default=None,
        type=str,
        help="Exclude disk(s) with target dev name (-x vda,vdb)",
    )
    opt.add_argument(
        "-f",
        "--socketfile",
        default=None,
        type=str,
        help="Use file for NBD Server socket instead of random file",
    )
    opt.add_argument(
        "-n",
        "--noprogress",
        default=False,
        help="Disable progress bar",
        action="store_true",
    )
    opt.add_argument(
        "-z",
        "--compress",
        default=False,
        help="Compress with lz4. (default: %(default)s)",
        action="store_true",
    )
    opt.add_argument(
        "-w",
        "--worker",
        type=int,
        default=None,
        help=(
            "Amount of concurrent workers used "
            "to backup multiple disks. (default: amount of disks)"
        ),
    )
    opt.add_argument(
        "-F",
        "--freeze-mountpoint",
        type=str,
        default=None,
        help=(
            "If qemu agent available, freeze only filesystems on specified mountpoints within"
            " virtual machine (default: all)"
        ),
    )
    opt.add_argument(
        "-e",
        "--strict",
        default=False,
        help=(
            "Change exit code if warnings occur during backup operation. "
            "(default: %(default)s)"
        ),
        action="store_true",
    )
    debopt = parser.add_argument_group("Debug options")
    debopt.add_argument(
        "-q",
        "--qemu",
        default=False,
        action="store_true",
        help="Use Qemu tools to query extents.",
    )
    debopt.add_argument(
        "-s",
        "--startonly",
        default=False,
        help="Only initialize backup job via libvirt, do not backup any data",
        action="store_true",
    )
    debopt.add_argument(
        "-k",
        "--killonly",
        default=False,
        help="Kill any running block job",
        action="store_true",
    )
    debopt.add_argument(
        "-p",
        "--printonly",
        default=False,
        help="Quit after printing extent information",
        action="store_true",
    )
    debopt.add_argument(
        "-v",
        "--verbose",
        default=False,
        help="Enable debug output",
        action="store_true",
    )
    debopt.add_argument(
        "-V",
        "--version",
        default=False,
        help="Show version and exit",
        action="version",
        version=__version__,
    )

    outHelper = outputhelper.outputHelper()
    lib = common.Common()
    args = lib.argparse(parser)

    args.stdout = args.output == "-"

    try:
        fileStream = getFileStream(args, outHelper)
    except outputhelper.exceptions.OutputException as e:
        logging.error("Cant open output file: [%s]", e)
        sys.exit(1)

    if args.worker is not None and args.worker < 1:
        args.worker = 1

    now = datetime.now().strftime("%m%d%Y%H%M%S")
    logFile = f"{args.output}/backup.{args.level}.{now}.log"
    fileLog = lib.getLogFile(logFile) or sys.exit(1)

    counter = logCount()
    lib.configLogger(args, fileLog, counter)

    lib.printVersion(__version__)

    logging.info("Backup level: [%s]", args.level)
    if args.compress:
        logging.info("Compression enabled")

    if args.stdout is True and args.type == "raw":
        logging.error("Output type raw not supported to stdout")
        sys.exit(1)

    if lib.targetIsEmpty(args) and args.level == "auto":
        logging.info("Backup mode auto, target folder is empty: executing full backup.")
        args.level = "full"
    elif not lib.targetIsEmpty(args) and args.level == "auto":
        if not lib.hasFullBackup(args):
            logging.error(
                "Cant execute switch to auto incremental backup: "
                "target folder seems not to include full backup."
            )
            sys.exit(1)
        logging.info("Backup mode auto: executing incremental backup.")
        args.level = "inc"
    elif not args.stdout and not args.startonly and not args.killonly:
        if not lib.targetIsEmpty(args):
            logging.error("Target directory must be empty for full or copy backup.")
            sys.exit(1)

    if args.raw and args.level in ("inc", "diff"):
        logging.error(
            "Raw disks cant be included during incremental or differencial backup."
        )
        sys.exit(1)

    if args.type == "raw" and args.level in ("inc", "diff"):
        logging.error(
            "Backup format raw does not support incremental or differencial backup"
        )
        sys.exit(1)

    if args.printonly is True:
        logging.info("Printing only extend information: enforce level copy")
        args.level = "copy"

    if hasPartial(args, lib):
        sys.exit(1)

    if not args.checkpointdir:
        args.checkpointdir = f"{args.output}/checkpoints"
    else:
        logging.info("Store checkpoints in: %s", args.checkpointdir)

    outHelper.Directory(args.checkpointdir)

    try:
        virtClient = libvirthelper.client(args)
        domObj = virtClient.getDomain(args.domain)
    except libvirthelper.exceptions.domainNotFound as e:
        logging.error("%s", e)
        sys.exit(1)
    except libvirthelper.exceptions.connectionFailed as e:
        logging.error("Cant connect libvirt daemon: %s", e)
        sys.exit(1)

    logging.info("Libvirt library version: %s", virtClient.libvirtVersion)

    if virtClient.hasIncrementalEnabled(domObj) is False:
        logging.error("Domain is missing required incremental-backup capability.")
        sys.exit(1)

    try:
        checkForeign(args, virtClient, domObj, lib)
    except exceptions.CheckpointException:
        sys.exit(1)

    setOfflineArguments(args, domObj)
    if args.offline is True and args.startonly is True:
        logging.error("Virtual machine is currently offline")
        logging.error("Virtual machine must be active for this function.")
        sys.exit(1)

    signal.signal(
        signal.SIGINT, partial(handleSignal, args, domObj, virtClient, logging)
    )

    vmConfig = virtClient.getDomainConfig(domObj)
    disks = virtClient.getDomainDisks(args, vmConfig) or (
        logging.error(
            "Domain has no disks attached which support changed block tracking."
        ),
        sys.exit(1),
    )
    if (
        not args.killonly
        and not args.offline
        and virtClient.blockJobActive(domObj, disks)
    ):
        logging.error("Detected an active backup operation for running domain.")
        logging.error("Check with [virsh domjobinfo %s]", args.domain)
        sys.exit(1)

    args.info = virtClient.getDomainInfo(vmConfig)
    logging.info(
        "Domain has %s disks attached which support changed block tracking.", len(disks)
    )
    if args.worker is None or args.worker > int(len(disks)):
        args.worker = int(len(disks))
    logging.info("Concurrent backup processes: [%s]", args.worker)

    if args.killonly is True:
        logging.info("Stopping backup job")
        if not virtClient.stopBackup(domObj):
            sys.exit(1)
        sys.exit(0)

    try:
        handleCheckpoints(args, virtClient, domObj, lib)
    except exceptions.CheckpointException as errmsg:
        logging.error(errmsg)
        sys.exit(1)

    logging.info("Temporary scratch file target directory: %s", args.scratchdir)

    outHelper.Directory(args.scratchdir)

    args.socketfile = lib.getSocketFile(args.socketfile)
    logging.info("NDB Endpoint socket: %s", args.socketfile)

    if args.offline is not True:
        try:
            logging.info("Starting backup job.")
            virtClient.startBackup(
                args,
                domObj,
                disks,
            )
            logging.debug("Backup job started, using socket: %s", args.socketfile)
        except Exception as e:
            logging.error(e)
            logging.exception(e)
            sys.exit(1)

    if args.level not in ("copy", "diff") and args.offline is False:
        logging.info("Started backup job with checkpoint, saving information.")
        try:
            saveCheckpointFile(args)
        except exceptions.CheckpointException as e:
            logging.error("Unable to append checkpoint file: %s", e)
            sys.exit(1)
        if args.printonly is False:
            if not virtClient.backupCheckpoint(args, domObj):
                virtClient.stopBackup(domObj)
                sys.exit(1)

    if args.startonly is True:
        logging.info("Started backup job for debugging, exiting.")
        sys.exit(0)

    try:
        with ThreadPoolExecutor(max_workers=args.worker) as executor:
            futures = {
                executor.submit(
                    backupDisk, args, disk, count, lib, fileStream, virtClient
                ): disk
                for count, disk in enumerate(disks)
            }
            for future in as_completed(futures):
                if future.result() is not True:
                    raise exceptions.DiskBackupFailed("Backup of one disk failed")
    except exceptions.BackupException as e:
        logging.error("Unable to backup Disk: %s", e)
        logging.exception(e)
    except Exception as e:
        logging.fatal("Unknown Exception during backup: %s", e)
        logging.exception(e)

    if args.offline is False:
        logging.info("Backup jobs finished, stopping backup task.")
        virtClient.stopBackup(domObj)

    if counter.count.errors > 0:
        logging.error("Error during backup")
        sys.exit(1)

    configFile = None
    if args.printonly is False:
        configFile = backupConfig(args, vmConfig)

    backupBootConfig(args, lib)

    if args.stdout is True and args.printonly is False:
        addFiles(args, configFile, fileStream, logFile)

    if counter.count.warnings > 0 and args.strict is True:
        logging.info(
            "[%s] Warnings detected during backup operation, forcing exit code 2",
            counter.count.warnings,
        )
        sys.exit(2)

    logging.info("Finished successfully")


def addFiles(args, configFile, zipStream, logFile):
    """Add backup log and other files to zip archive"""
    if configFile is not None:
        logging.info("Adding vm config to zipfile")
        zipStream.zipStream.write(configFile, configFile)
    if args.level in ("full", "inc"):
        logging.info("Adding checkpoint info to zipfile")
        zipStream.zipStream.write(args.cpt.file, args.cpt.file)
        for dirname, _, files in os.walk(args.checkpointdir):
            zipStream.zipStream.write(dirname)
            for filename in files:
                zipStream.zipStream.write(os.path.join(dirname, filename))

    for setting in args.info:
        if args.info[setting] is not None:
            logging.info(
                "Adding additional config file [%s] to zipfile", args.info[setting]
            )
            zipStream.zipStream.write(
                args.info[setting], os.path.basename(args.info[setting])
            )

    logging.info("Adding backup log [%s] to zipfile", logFile)
    zipStream.zipStream.write(logFile, logFile)


def getIdent(args):
    """Used to get an uniqe identifier for target files,
    usually checkpoint name is used, but if no checkpoint
    is created, we use timestamp"""
    ident = args.cpt.name
    if args.level == "diff":
        ident = int(time())

    return ident


def backupConfig(args, vmConfig):
    """Save domain config file"""
    ident = getIdent(args)
    configFile = f"{args.output}/vmconfig.{ident}.xml"
    logging.info("Saving VM config to: [%s]", configFile)
    try:
        with outputhelper.openfile(configFile, "w") as fh:
            fh.write(vmConfig)
        return configFile
    except:
        logging.error("Error saving VM config.")
        raise


def backupBootConfig(args, lib):
    """Save domain nvram and loader"""
    ident = getIdent(args)

    for setting in args.info.keys():
        if args.info[setting] is not None:
            fileBase = os.path.basename(args.info[setting])
            tfile = f"{args.output}/{fileBase}.{ident}"
            logging.info(
                "Save additional boot config file [%s] to: [%s]", setting, tfile
            )
            lib.copy(args.info[setting], tfile)


def setMetaContext(args, disk):
    """Set meta context passed to nbd server based on
    backup type"""
    metaContext = None
    if args.level in ("inc", "diff"):
        if args.offline is True:
            metaContext = f"qemu:dirty-bitmap:{args.cpt.name}"
        else:
            metaContext = f"qemu:dirty-bitmap:backup-{disk.target}"

        logging.info("INC/DIFF backup: set context to %s", metaContext)

    return metaContext


def setStreamType(args, disk):
    """Set target stream type"""
    if disk.format != "raw":
        streamType = args.type
    else:
        streamType = "raw"

    return streamType


def setTargetFile(args, disk):
    """Set Target file name to write"""
    if args.level in ("full", "copy"):
        if disk.format == "raw":
            level = "copy"
        else:
            level = args.level
        targetFile = f"{args.output}/{disk.target}.{level}.data"
    elif args.level in ("inc", "diff"):
        cptName = getIdent(args)
        targetFile = f"{args.output}/{disk.target}.{args.level}.{cptName}.data"

    targetFilePartial = f"{targetFile}.partial"

    return targetFile, targetFilePartial


def getWriter(args, fileStream, targetFile, targetFilePartial):
    """Open target file based on output writer"""
    if args.stdout is True:
        targetFile = os.path.basename(targetFile)
        logging.info("Write data to zip archive")
        writer = fileStream.open(targetFile)
    else:
        logging.info("Write data to target file: %s", targetFilePartial)
        writer = fileStream.open(targetFilePartial)

    return writer


def getExtentHandler(args, cType, connection):
    """Query dirty blocks either via qemu client or self
    implemented extend handler"""
    if args.qemu:
        logging.info("Using qemu tools to query extents")
        extentHandler = extenthandler.ExtentHandler(
            qemuhelper.qemuHelper(cType.exportName), cType
        )
    else:
        extentHandler = extenthandler.ExtentHandler(connection, cType)

    return extentHandler


def renamePartial(targetFilePartial, targetFile):
    """After backup, move .partial file to real
    target file"""
    try:
        os.rename(targetFilePartial, targetFile)
    except OSError as e:
        raise exceptions.DiskBackupFailed(f"Unable to rename file: {e}") from e


def startOfflineNBD(args, disk):
    """Start background qemu-nbd process used during backup
    if domain is offline"""
    bitMap = None
    if args.level in ("inc", "diff"):
        bitMap = args.cpt.name
    args.socketfile = f"{args.socketfile}.{disk.target}"
    logging.info("Offline backup, starting NDB Service")
    try:
        nbdProc = qemuhelper.qemuHelper(disk.target).startBackupNbdServer(
            disk.format, disk.path, args.socketfile, bitMap
        )
        logging.info("NDB Service started, PID: [%s]", nbdProc.pid)
        return nbdProc
    except qemuhelper.exceptions.QemuHelperError as e:
        raise exceptions.DiskBackupFailed(e)


def backupDisk(args, disk, count, lib, fileStream, virtClient):
    """Backup domain disk data."""

    stream = streamer.SparseStream(types)
    sTypes = types.SparseStreamTypes()

    current_thread().name = disk.target
    streamType = setStreamType(args, disk)
    metaContext = setMetaContext(args, disk)

    if args.offline is True:
        nbdProc = startOfflineNBD(args, disk)

    cType = nbdhelper.nbdConnUnix(disk.target, metaContext, args.socketfile)
    if virtClient.remoteHost is not None:
        cType = nbdhelper.nbdConnTCP(disk.target, metaContext, virtClient.remoteHost)
    else:
        cType = nbdhelper.nbdConnUnix(disk.target, metaContext, args.socketfile)
    nbdClient = nbdhelper.nbdClient(cType)
    try:
        connection = nbdClient.waitForServer()
    except nbdhelper.exceptions.NbdClientException as e:
        raise exceptions.DiskBackupFailed(
            f"NBD endpoint: {cType}: connection failed: {e}"
        )

    extentHandler = getExtentHandler(args, cType, connection)
    extents = extentHandler.queryBlockStatus()
    diskSize = connection.get_size()

    if extents is None:
        logging.error("No extents found")
        return True

    thinBackupSize = sum(extent.length for extent in extents if extent.data is True)
    logging.info("Got %s extents to backup.", len(extents))
    logging.debug("%s", lib.dumpExtentJson(extents))
    logging.info("%s bytes disk size", diskSize)
    logging.info("%s bytes of data extents to backup", thinBackupSize)
    if args.printonly is True:
        nbdClient.disconnect()
        return True

    if args.level in ("inc", "diff") and thinBackupSize == 0:
        logging.info("No dirty blocks found")
        args.noprogress = True

    targetFile, targetFilePartial = setTargetFile(args, disk)
    writer = getWriter(args, fileStream, targetFile, targetFilePartial)

    if streamType == "raw":
        logging.info("Creating full provisioned raw backup image")
        try:
            writer.truncate(diskSize)
        except OSError as e:
            raise exceptions.DiskBackupWriterException(
                f"Unable to truncate target file: {e}"
            ) from e
        writer.seek(0)
    else:
        logging.info("Creating thin provisioned stream backup image")
        metadata = stream.dumpMetadata(
            diskSize,
            thinBackupSize,
            disk,
            args.cpt.name,
            args.cpt.parent,
            (args.level in ("inc", "diff")),
            args.compress,
        )
        stream.writeFrame(writer, sTypes.META, 0, len(metadata))
        writer.write(metadata)
        writer.write(sTypes.TERM)

    progressBar = lib.progressBar(
        thinBackupSize, f"saving disk {disk.target}", args, count=count
    )
    compressedSizes = []
    for save in extents:
        if save.data is True:
            if streamType == "stream":
                stream.writeFrame(writer, sTypes.DATA, save.offset, save.length)
                logging.debug(
                    "Read data from: start %s, length: %s", save.offset, save.length
                )

            cSizes = None

            if save.length >= nbdClient.maxRequestSize:
                logging.debug(
                    "Chunked data read from: start %s, length: %s",
                    save.offset,
                    save.length,
                )
                size, cSizes = lib.writeChunk(
                    writer,
                    save.offset,
                    save.length,
                    nbdClient.maxRequestSize,
                    connection,
                    streamType,
                    args.compress,
                )
            else:
                size = lib.writeBlock(
                    writer,
                    save.offset,
                    save.length,
                    connection,
                    streamType,
                    args.compress,
                )
                if streamType == "raw":
                    size = writer.seek(save.offset)

            if streamType == "stream":
                writer.write(sTypes.TERM)
                if args.compress is True:
                    logging.debug("Compressed size: %s", size)
                    if cSizes:
                        blockList = {}
                        blockList[size] = cSizes
                        compressedSizes.append(blockList)
                    else:
                        compressedSizes.append(size)
                else:
                    assert size == save.length

            progressBar.update(save.length)
        else:
            if streamType == "raw":
                writer.seek(save.offset)
            elif streamType == "stream" and args.level not in ("inc", "diff"):
                stream.writeFrame(writer, sTypes.ZERO, save.offset, save.length)
    if streamType == "stream":
        stream.writeFrame(writer, sTypes.STOP, 0, 0)
        if args.compress:
            stream.writeCompressionTrailer(writer, compressedSizes)

    progressBar.close()
    logging.debug("Closing write handle.")
    writer.close()
    nbdClient.disconnect()
    if args.offline is True:
        logging.info("Stopping NBD Service")
        lib.killProc(nbdProc.pid)
    if args.stdout is False:
        if args.noprogress is True:
            logging.info(
                "Backup of disk %s finished, file: %s", disk.target, targetFile
            )
        renamePartial(targetFilePartial, targetFile)

    return True


if __name__ == "__main__":
    main()
