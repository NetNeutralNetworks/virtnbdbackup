#!/usr/bin/python3
"""
    Copyright (C) 2021  Michael Ablassmeier <abi@grinser.de>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""
import os
import sys
import json
import signal
import logging
import argparse
from datetime import datetime
from functools import partial
from threading import current_thread
from concurrent.futures import ThreadPoolExecutor, as_completed

import libvirtnbdbackup.common as common
import libvirtnbdbackup.nbdhelper as nbdhelper
import libvirtnbdbackup.extenthandler as extenthandler
import libvirtnbdbackup.sparsestream as sparsestream
import libvirtnbdbackup.qemuhelper as qemuhelper
import libvirtnbdbackup.libvirthelper as libvirthelper
import libvirtnbdbackup.outputhelper as outputhelper

from libvirtnbdbackup import __version__


def handleSignal(args, domObj, virtClient, log, signum, frame):
    """Catch signal, attempt to stop running backup job."""
    log.error("Caught signal: %s", signum)
    log.error("Cleanup: Stopping backup job")
    if args.offline is not True:
        virtClient.stopBackup(domObj)
    sys.exit(1)


def main():
    """Handle backup operation"""
    parser = argparse.ArgumentParser(description="Backup libvirt/qemu virtual machines")
    parser.add_argument(
        "-d", "--domain", required=True, type=str, help="Domain to backup"
    )
    parser.add_argument(
        "-l",
        "--level",
        default="copy",
        choices=["copy", "full", "inc"],
        type=str,
        help="Backup level. (default: %(default)s)",
    )
    parser.add_argument(
        "-t",
        "--type",
        default="stream",
        type=str,
        choices=["stream", "raw"],
        help="Output type: stream or raw. (default: %(default)s)",
    )
    parser.add_argument(
        "-r",
        "--raw",
        default=False,
        action="store_true",
        help="Include full provisioned disk images in backup. (default: %(default)s)",
    )
    parser.add_argument(
        "-o", "--output", required=True, type=str, help="Output target directory"
    )
    parser.add_argument(
        "-C",
        "--checkpointdir",
        required=False,
        default=None,
        type=str,
        help="Persistent libvirt checkpoint storage directory",
    )
    parser.add_argument(
        "-S",
        "--scratchdir",
        default="/var/tmp",
        required=False,
        type=str,
        help="Target directory for temporary scratch file. (default: %(default)s)",
    )
    parser.add_argument(
        "-q",
        "--qemu",
        default=False,
        action="store_true",
        help="Use Qemu tools to query extents",
    )
    parser.add_argument(
        "-i",
        "--include",
        default=None,
        type=str,
        help="Backup only disk with target dev name (-i vda)",
    )
    parser.add_argument(
        "-x",
        "--exclude",
        default=None,
        type=str,
        help="Exclude disk(s) with target dev name (-x vda,vdb)",
    )
    parser.add_argument(
        "-c",
        "--checkpoint",
        default=False,
        help="During incremental backup, use specified checkpoint as parent",
        type=str,
    )
    parser.add_argument(
        "-s",
        "--startonly",
        default=False,
        help="Only initialize backup job via libvirt, do not backup any data",
        action="store_true",
    )
    parser.add_argument(
        "-k",
        "--killonly",
        default=False,
        help="Kill any running block job",
        action="store_true",
    )
    parser.add_argument(
        "-p",
        "--printonly",
        default=False,
        help="Quit after printing extent information",
        action="store_true",
    )
    parser.add_argument(
        "-f",
        "--socketfile",
        default=None,
        type=str,
        help="Use specified file for NBD Server socket instead of random file",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        default=False,
        help="Enable debug output",
        action="store_true",
    )
    parser.add_argument(
        "-n",
        "--noprogress",
        default=False,
        help="Disable progress bar",
        action="store_true",
    )
    parser.add_argument(
        "-z",
        "--compress",
        default=False,
        help="Compress with lz4. (default: %(default)s)",
        action="store_true",
    )
    parser.add_argument(
        "-w",
        "--worker",
        type=int,
        default=None,
        help="Amount of concurrent workers used to backup multiple disks. (default: amount of disks)",
    )

    outHelper = outputhelper.outputHelper()
    lib = common.Common()
    args = lib.argparse(parser)

    toStdout = args.output == "-"

    zipStream = None
    if toStdout is False:
        outHelper.Directory(args.output)
    else:
        zipStream = outHelper.Zip()
        args.output = "./"
        args.worker = 1
        args.raw = False

    if args.worker is not None and args.worker < 1:
        args.worker = 1

    logFile = "%s/backup.%s.%s.log" % (
        args.output,
        args.level,
        datetime.now().strftime("%m%d%Y%H%M%S"),
    )

    logging.basicConfig(
        level=lib.setLogLevel(args.verbose),
        format=lib.logFormat,
        datefmt=lib.logDateFormat,
        handlers=[
            logging.FileHandler(logFile),
            logging.StreamHandler(stream=sys.stderr),
        ],
    )

    lib.printVersion(__version__)

    logging.info("Backup level: [%s]", args.level)
    if args.compress:
        logging.info("Compression enabled")

    if toStdout is True and args.type == "raw":
        logging.error("Output type raw not supported to stdout")
        sys.exit(1)

    if not toStdout and not args.startonly and not args.killonly:
        if not lib.targetIsEmpty(args):
            logging.error("Target directory must empty for full or copy backup.")
            sys.exit(1)

    if args.raw and args.level == "inc":
        logging.error("Raw disks cant be included during incremental backup.")
        sys.exit(1)

    if args.type == "raw" and args.level == "inc":
        logging.error("Backup format raw does not support incremental backup")
        sys.exit(1)

    if args.printonly is True:
        logging.info("Printing only extend information: enforce level copy")
        args.level = "copy"

    if args.level == "inc" and toStdout is False and lib.partialBackup(args) is True:
        logging.error("Partial backup found in target directory: %s", args.output)
        logging.error("One of the last backups seems to have failed.")
        logging.error("Consider re-executing full backup.")
        sys.exit(1)

    if not args.checkpointdir:
        args.checkpointdir = f"{args.output}/checkpoints"
    else:
        logging.info("Store checkpoints in: %s", args.checkpointdir)

    outHelper.Directory(args.checkpointdir)

    virtClient = libvirthelper.client()
    try:
        domObj = virtClient.getDomain(args.domain)
    except Exception as e:
        logging.error("Unable to get domain information: %s", e)
        sys.exit(1)

    if virtClient.hasIncrementalEnabled(domObj) is False:
        logging.error("Domain is missing required incremental-backup capability.")
        sys.exit(1)

    args.offline = False
    if virtClient.domainOffline(domObj) is True:
        logging.warning("Domain is offline, resetting backup options")
        args.level = "copy"
        logging.info("Backup level: [%s]", args.level)
        args.qemu = True
        args.worker = 1
        args.offline = True

    signal.signal(
        signal.SIGINT, partial(handleSignal, args, domObj, virtClient, logging)
    )

    vmConfig = virtClient.getDomainConfig(domObj)
    disks = virtClient.getDomainDisks(vmConfig, args.exclude, args.include, args.raw)

    if not disks:
        logging.error(
            "Domain has no disks attached which support changed block tracking."
        )
        sys.exit(1)

    logging.info(
        "Domain has %s disks attached which support changed block tracking.", len(disks)
    )
    if args.worker is None:
        args.worker = int(len(disks))
    logging.info("Concurrent backup processes: [%s]", args.worker)

    if args.killonly is True:
        logging.info("Stopping backup job")
        try:
            virtClient.stopBackup(domObj)
            sys.exit(0)
        except Exception as e:
            logging.exception(e)
            sys.exit(1)

    checkpointName = f"{lib.checkpointName}.0"
    parentCheckpoint = False
    checkpoints = []
    cptFile = "%s/%s.cpt" % (args.output, args.domain)
    if os.path.exists(cptFile):
        with open(cptFile, "r") as cptFh:
            checkpoints = json.loads(cptFh.read())

    if args.level != "copy":
        logging.info("Check for missing checkpoints from: %s", args.checkpointdir)
        if virtClient.redefineCheckpoints(domObj, args) is False:
            logging.error("Unable to redefine checkpoints.")
            sys.exit(1)

        logging.info("Checkpoint handling")
        if args.level == "full" and checkpoints:
            logging.info("Removing all existent checkpoints before full backup")
            virtClient.removeAllCheckpoints(domObj, checkpoints, args)
            os.remove(cptFile)
            checkpoints = []
        elif args.level == "full" and len(checkpoints) < 1:
            virtClient.removeAllCheckpoints(domObj, None, args)
            checkpoints = []

        if checkpoints and args.level == "inc":
            nextCpt = len(checkpoints)
            checkpointName = "%s.%s" % (lib.checkpointName, nextCpt)
            if args.checkpoint is not False:
                logging.info("Overriding parent checkpoint: %s", args.checkpoint)
                parentCheckpoint = args.checkpoint
            else:
                parentCheckpoint = checkpoints[-1]
            logging.info("Next checkpoint id: %s", nextCpt)
            logging.info("Parent checkpoint name %s", parentCheckpoint)

        if args.level == "inc" and len(checkpoints) < 1:
            logging.error("No prior checkpoints found, execute full backup first")
            sys.exit(1)

        logging.info("Using checkpoint name: %s", checkpointName)

    logging.info("Temporary scratch file target directory: %s", args.scratchdir)

    outHelper.Directory(args.scratchdir)

    backupSocket = lib.getSocketFile(args.socketfile)
    logging.info("NDB Endpoint socket: %s", backupSocket)

    if virtClient.domainOffline(domObj) is not True:
        try:
            logging.info("Starting backup job.")
            virtClient.startBackup(
                domObj,
                disks,
                args.level,
                checkpointName,
                parentCheckpoint,
                args.scratchdir,
                backupSocket,
            )
            logging.debug("Backup job started, using socket: %s", backupSocket)
        except Exception as e:
            logging.error(e)
            sys.exit(1)

    if args.level != "copy":
        logging.info("Started backup job with checkpoint, saving information.")
        if not checkpoints:
            checkpoints = []
        checkpoints.append(checkpointName)
        with open(cptFile, "w") as cFw:
            cFw.write(json.dumps(checkpoints))
        if args.printonly is False:
            if not virtClient.backupCheckpoint(domObj, args, checkpointName):
                virtClient.stopBackup(domObj)
                sys.exit(1)

    if args.startonly is True:
        logging.info("Started backup job for debugging, exiting.")
        sys.exit(0)

    try:
        with ThreadPoolExecutor(max_workers=args.worker) as executor:
            futures = {
                executor.submit(
                    backupDisk,
                    disk,
                    count,
                    args,
                    lib,
                    checkpointName,
                    parentCheckpoint,
                    backupSocket,
                    zipStream,
                    toStdout,
                ): disk
                for count, disk in enumerate(disks)
            }
            for future in as_completed(futures):
                if future.result() is not True:
                    raise RuntimeError("Backup of one disk failed")
    except Exception as e:
        logging.error("Unable to backup Disk: %s", e)
        logging.exception(e)
        if virtClient.domainOffline(domObj) is False:
            virtClient.stopBackup(domObj)
        sys.exit(1)

    configFile = None
    if args.printonly is False:
        configFile = backupConfig(vmConfig, args, checkpointName)

    if virtClient.domainOffline(domObj) is False:
        logging.info("Backup jobs finished, stopping backup task.")
        ret = virtClient.stopBackup(domObj)
        if ret != 0:
            logging.warning("Unable to stop backup task, return: %s", e)

    logging.info("Finished")

    if toStdout is True and args.printonly is False:
        addFiles(configFile, zipStream, cptFile, logFile, args)


def addFiles(configFile, zipStream, cptFile, logFile, args):
    """Add backup log and other files to zip archive"""
    if configFile is not None:
        logging.info("Adding vm config to zipfile")
        zipStream.zipStream.write(configFile, configFile)
    if args.level in ("full", "inc"):
        logging.info("Adding checkpoint info to zipfile")
        zipStream.zipStream.write(cptFile, cptFile)
        for dirname, _, files in os.walk(args.checkpointdir):
            zipStream.zipStream.write(dirname)
            for filename in files:
                zipStream.zipStream.write(os.path.join(dirname, filename))
    logging.info("Adding backup log to zipfile")
    zipStream.zipStream.write(logFile, logFile)


def backupConfig(vmConfig, args, checkpointName):
    """Save domain config file"""
    configFile = "%s/vmconfig.%s.xml" % (args.output, checkpointName)
    logging.info("Saving VM config to: %s", configFile)
    try:
        with open(configFile, "w") as configFh:
            configFh.write(vmConfig)
        return configFile
    except Exception as e:
        logging.error("Unable to save VM config: %s", e)
        logging.exception(e)
        sys.exit(1)


def backupDisk(
    disk,
    count,
    args,
    lib,
    checkpointName,
    parentCheckpoint,
    backupSocket,
    zipStream,
    toStdout,
):
    """Backup domain disk data."""

    stream = sparsestream.SparseStream()
    sTypes = sparsestream.SparseStreamTypes()

    current_thread().name = disk.diskTarget
    if disk.diskFormat != "raw":
        streamType = args.type
    else:
        streamType = "raw"

    metaContext = None
    if args.level == "inc":
        metaContext = "qemu:dirty-bitmap:backup-%s" % disk.diskTarget
        logging.info("INC backup: set context to %s", metaContext)

    if args.offline is True:
        logging.info("Offline backup, starting NDB Service")
        pid = qemuhelper.qemuHelper(disk.diskTarget).startBackupNbdServer(
            disk.diskFormat, disk.diskPath, backupSocket
        )
        logging.info("NDB Service PID: [%s]", pid)

    nbdClient = nbdhelper.nbdClient(disk.diskTarget, metaContext, backupSocket)
    connection = nbdClient.waitForServer()
    if not connection:
        raise RuntimeError(f"Error connecting to nbd endpoint: {backupSocket}")

    if args.qemu and args.level != "inc":
        logging.info("Using qemu tools to query extents")
        extentHandler = extenthandler.ExtentHandler(
            qemuhelper.qemuHelper(disk.diskTarget), metaContext, backupSocket
        )
    else:
        extentHandler = extenthandler.ExtentHandler(
            connection, metaContext, backupSocket
        )
    extents = extentHandler.queryBlockStatus()
    diskSize = connection.get_size()

    if extents is None:
        logging.error("No extents found")
        return True

    thinBackupSize = sum([extent.length for extent in extents if extent.data is True])
    logging.info("Got %s extents to backup.", len(extents))
    logging.debug("%s", lib.dumpExtentJson(extents))
    logging.info("%s bytes disk size", diskSize)
    logging.info("%s bytes of data extents to backup", thinBackupSize)
    if args.printonly is True:
        nbdClient.disconnect()
        return True

    if args.level == "inc" and thinBackupSize == 0:
        logging.info("No dirty blocks found")
        args.noprogress = True

    if args.level in ("full", "copy"):
        if disk.diskFormat == "raw":
            level = "copy"
        else:
            level = args.level
        targetFile = "%s/%s.%s.data" % (args.output, disk.diskTarget, level)
    elif args.level == "inc":
        targetFile = "%s/%s.inc.%s.data" % (
            args.output,
            disk.diskTarget,
            checkpointName,
        )

    if toStdout is True:
        targetFile = os.path.basename(targetFile)
        writer = zipStream.open(targetFile)
        if writer is False:
            raise RuntimeError("Unable to open zip file in stream")
    else:
        targetFilePartial = "%s.partial" % targetFile
        logging.info("Write data to target file: %s", targetFilePartial)
        try:
            writer = open(targetFilePartial, "wb")
        except Exception as e:
            raise RuntimeError(f"Unable to open target file: {e}") from e

    if streamType == "raw":
        logging.info("Creating full provisioned raw backup image")
        try:
            writer.truncate(diskSize)
        except Exception as e:
            raise RuntimeError(f"Unable to truncate target file: {e}") from e
        writer.seek(0)
    else:
        logging.info("Creating thin provisioned stream backup image")
        inc = args.level == "inc"
        metadata = stream.dumpMetadata(
            diskSize,
            thinBackupSize,
            disk.diskTarget,
            checkpointName,
            parentCheckpoint,
            inc,
            args.compress,
        )
        stream.writeFrame(writer, sTypes.META, 0, len(metadata))
        writer.write(metadata)
        writer.write(sTypes.TERM)

    progressBar = lib.progressBar(
        thinBackupSize, f"saving disk {disk.diskTarget}", args, count=count
    )
    compressedSizes = []
    for save in extents:
        if save.data is True:
            if streamType == "stream":
                stream.writeFrame(writer, sTypes.DATA, save.offset, save.length)
                logging.debug(
                    "Read data from: start %s, length: %s", save.offset, save.length
                )

            cSizes = None

            if save.length >= nbdClient.maxRequestSize:
                logging.debug(
                    "Chunked data read from: start %s, length: %s",
                    save.offset,
                    save.length,
                )
                size, cSizes = lib.writeChunk(
                    writer,
                    save.offset,
                    save.length,
                    nbdClient.maxRequestSize,
                    connection,
                    streamType,
                    args.compress,
                )
            else:
                size = lib.writeBlock(
                    writer,
                    save.offset,
                    save.length,
                    connection,
                    streamType,
                    args.compress,
                )
                if streamType == "raw":
                    size = writer.seek(save.offset)

            if streamType == "stream":
                writer.write(sTypes.TERM)
                if args.compress is True:
                    logging.debug("Compressed size: %s", size)
                    if cSizes:
                        blockList = {}
                        blockList[size] = cSizes
                        compressedSizes.append(blockList)
                    else:
                        compressedSizes.append(size)
                else:
                    assert size == save.length

            progressBar.update(save.length)
        else:
            if streamType == "raw":
                writer.seek(save.offset)
            elif streamType == "stream" and args.level != "inc":
                stream.writeFrame(writer, sTypes.ZERO, save.offset, save.length)
    if streamType == "stream":
        stream.writeFrame(writer, sTypes.STOP, 0, 0)
        if args.compress:
            stream.writeCompressionTrailer(writer, compressedSizes)

    progressBar.close()
    logging.debug("Closing write handle.")
    writer.close()
    nbdClient.disconnect()
    if args.offline is True:
        logging.info("Stopping NBD Service with pid: [%s]", pid)
        lib.killPid(pid)
    if toStdout is False:
        try:
            os.rename(targetFilePartial, targetFile)
            if args.noprogress is True:
                logging.info(
                    "Backup of disk %s finished, file: %s", disk.diskTarget, targetFile
                )
        except OSError as e:
            logging.error("Unable to rename file: %s", e)
            sys.exit(1)

    return True


if __name__ == "__main__":
    main()
